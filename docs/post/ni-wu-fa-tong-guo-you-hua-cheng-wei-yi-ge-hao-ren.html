<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    
    <link rel="icon" href="https://github.githubassets.com/favicons/favicon.svg"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content=">原文链接：https://www.vox.com/the-highlight/387570/moral-optimization

我每次都试图做出完美的道德选择。">
<meta property="og:title" content="你无法通过优化成为一个好人">
<meta property="og:description" content=">原文链接：https://www.vox.com/the-highlight/387570/moral-optimization

我每次都试图做出完美的道德选择。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://chenqx33.github.io/post/ni-wu-fa-tong-guo-you-hua-cheng-wei-yi-ge-hao-ren.html">
<meta property="og:image" content="https://github.githubassets.com/favicons/favicon.svg">
<title>你无法通过优化成为一个好人</title>



</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}

</style>




<body>
    <div id="header">
<h1 class="postTitle">你无法通过优化成为一个好人</h1>
<div class="title-right">
    <a href="https://chenqx33.github.io" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/chenqx33/chenqx33.github.io/issues/6" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><blockquote>
<p>原文链接：<a href="https://www.vox.com/the-highlight/387570/moral-optimization" rel="nofollow">https://www.vox.com/the-highlight/387570/moral-optimization</a></p>
</blockquote>
<p>我每次都试图做出完美的道德选择。这侵蚀了我的人性。<br>
我是一个正在恢复中的优化者。<br>
过去几年里，我花了大量时间纠结于每一个决定，因为我觉得自己必须做到最好。不是还行的事，不是好事——而是道德上最好的事。</p>
<p>我停止了一部儿童小说的创作，因为开始怀疑它对任何人都不会有帮助。我责备自己没有每天冥想，尽管我知道这能让我成为一个更善良的人。我花了一年时间为一段分手哭泣，因为我害怕自己刚刚失去了最佳的灵魂伴侣，现在注定要过上一种次优的生活，一种无法达到其应有意义、未能充分发挥潜力的生活。<br>
我以为可能只是我这样，一个焦虑的千禧一代，带着完美主义倾向。但后来我注意到其他人也有同样的思维方式。</p>
<p>有位朋友总是在晚餐时烦恼，担心自己选择的职业能否对世界产生足够大的积极影响。另一位朋友将一天划分为 15 分钟的增量，并记录下每一刻所做的事情，以免浪费任何时间。还有一位朋友——我最好的朋友——哭着打电话给我，因为尽管她花了数月时间悉心照料伴侣垂危的母亲，却仍担心自己未能让她的最后时光尽可能快乐。</p>
<p>“我的情绪妨碍了我，”她自责道。“我真希望自己能像个机器人一样。”</p>
<p>我特别注意到，认同有效利他主义（EA）的同龄人中存在这种思维方式。有效利他主义是一场社会运动，其核心在于利用数据和理性来找出如何“更好地行善”或“尽你所能做最大的善事”，引用两位 EA 主要思想家的书名。该运动敦促人们向每美元能拯救最多生命的慈善机构捐款。我听到其追随者哀叹，当他们走过无家可归者时感到多么糟糕，内心涌起帮助的冲动，却强迫自己不去行动，因为他们的一美元能为低收入国家的贫困人口带来更大的益处。</p>
<p>这一切感觉不仅仅是许多人之前听说过的“优化文化”。它不是那种追求身体完美，推动你接受 Soylent 和补充剂、间歇性禁食和冰浴、Fitbits、Apple Watches 和 Oura Rings 的文化。它也不是那种专注于微调心灵，推动你尝试智能药物、多巴胺禁食和幸福追踪的文化。</p>
<p>这是优化文化的另一条线索，虽较少被分析却更为雄心勃勃，因为它不仅针对身体或心灵，而是直指圣杯：你的灵魂。这是关于道德优化的探讨。</p>
<p>这种思维方式在象牙塔中和街头巷尾一样普遍。带有功利主义倾向的哲学家告诉我们，仅仅做好事是不够的——我们必须尽可能做到最好。我们必须从数学上量化道德善行，以便能够最大化它。如今，这种驱动力在越来越多的圈子里显现出来，从利用技术“优化”冥想以期成为更好人的精神追求者，到试图将伦理编程入机器的人工智能研究者。</p>
<p>我想了解这个想法的来源，以便弄清楚为什么我们中的许多人似乎越来越执着于它——这样我就能诚实地评估它的优点。我们的道德生活可以被优化吗？如果可以，应该这样做吗？还是我们已经将优化推向了其最佳极限之外？</p>
<h1>我们如何开始相信道德优化</h1>
<p>“我们正处于一条长达 400 年的趋势线的顶端，”犹他大学的哲学家 C. Thi Nguyen 告诉我。他解释说，优化的故事实际上是数据的故事：它是如何被发明的，以及在过去几个世纪中是如何发展的。</p>
<p>正如历史学家玛丽·普维在她的著作《现代事实的历史》中所论述的那样，这一故事可追溯至 16 世纪，当时欧洲人提出了一个极具吸引力且革命性的知识项目——复式记账法。这一新型会计体系强调以精确、客观、可量化的方式记录每位商人的活动，使得任何人在任何地点都能进行核实。换言之，它开创了数据的概念。</p>
<h2>从一开始，人们就将优化视为一种神圣的力量。</h2>
<p>这为 17 世纪和 18 世纪的巨大智力发展铺平了道路——对于聪明的欧洲人来说，那是一个非常激动人心的时代。那是理性时代！启蒙时代！像弗朗西斯·培根和约翰内斯·开普勒这样的人看到了簿记的创新，并认为：这种将世界分割成可量化和可验证的数据块的方式非常棒。我们应该在我们正在构建的这个名为科学方法的新事物中模仿它。</p>
<p>与此同时，17 世纪的哲学家布莱兹·帕斯卡尔提出了一种概率性的数据处理方法，体现在如今著名的“帕斯卡尔赌注”中：如果你不服从上帝，而后来发现上帝并不存在，那也没什么大不了的；但如果上帝有可能存在，你的信仰就可能决定你是永远上天堂还是下地狱——所以，相信上帝是值得的！（科学哲学家伊恩·哈金称帕斯卡尔为世界上第一位统计学家，并称他的赌注是“对决策理论首次深入理解的贡献”。）</p>
<p>同样重要的是，艾萨克·牛顿和戈特弗里德·威廉·莱布尼茨正在创立微积分，这为人类提供了一种新的能力，即在给定的约束条件下找出可以实现的最大值——换句话说，就是优化。</p>
<p>从一开始，人们就将优化视为一种神圣的力量。</p>
<p>1712 年，数学家塞缪尔·柯尼希研究了蜂巢的复杂蜂窝结构。他思考：蜜蜂是否已经找到了如何用最少的蜡创造最多细胞的方法？他计算得出，它们确实做到了。那些毛茸茸、嗡嗡作响的优化者！法国科学院对这种最优结构印象深刻，以至于它被宣布为神圣指引或智能设计的证据。</p>
<p>很快，人们开始尝试将几乎所有事物数学化，从医学到神学再到道德哲学。这是一种为你的主张赋予客观真理光泽的方式。</p>
<p>以爱尔兰哲学家弗朗西斯·哈奇森为例，他首次提出了功利主义的经典口号——行为应促进“最大多数人的最大幸福”。1725 年，他写了一本书，试图将道德简化为数学公式，例如：</p>
<blockquote>
<p>任何行为者的道德重要性，或其产生的公共善的数量，是其仁慈与能力的复合比率：或（用字母代替词语，如 M = 善的矩，μ = 恶的矩）M = B × A。</p>
</blockquote>
<p>功利主义哲学家杰里米·边沁，追随哈奇森的足迹，也试图创建一种“幸福计算法”：一种用数学来确定行为道德地位的方法。他认为，行为在最大化幸福或快乐的程度内是道德的；事实上，正是边沁发明了“最大化”这个词。他主张伦理学和经济学都应致力于最大化效用（即幸福或满足感）：只需计算每项政策或行动能产生多少效用，然后选择产生最多效用的那个。这一论点至今对道德哲学和经济学产生了持久的影响。</p>
<p>与此同时，工业革命正在兴起。像亚当·斯密这样的经济学家提出了提高效率和最大化利润的方法。随着消费资本主义的繁荣，经济增长迅猛。在工业革命后的两个世纪里，生活水平提高，极端贫困大幅减少。对于欧洲的工业化国家来说，经济领域的优化似乎取得了巨大成功。美国引入并采纳了工厂流水线，带来了如亨利·福特的 T 型车等进步。</p>
<p>随后，在 20 世纪，数据故事迎来了一个新的转折点：计算机技术的重大进步。计算能力的增长使得分析大量数据并以更高精度建模成为可能——例如在二战期间破译纳粹密码，或处理美国人口普查。到了 20 世纪末，计算机从政府所有、房间大小的庞然大物变成了适合普通家庭使用的经济实惠的小工具。</p>
<p>随着互联网的发明，所有这些普通人开始生成大量数据。每一次网络搜索、每一次聊天、每一次在线购物都成为了一个数据点，因此到了 20 世纪 90 年代，谈论“大数据”成为可能。这进一步将优化的梦想推向了极致。硅谷开始敦促你量化身心的每一个方面，因为你对自身机械功能的数据掌握得越多，就越能优化你这个“机器”。</p>
<p>但对于数据爱好者和潜在的优化者来说，最大的“收获”始终是灵魂。随着计算技术的所有进步，实现最优道德的古老梦想颤栗着苏醒。</p>
<p>如今，这个梦想正被数据故事的最新篇章——人工智能——注入强劲动力。人类首次不仅能幻想以更高的精度模拟世界，还能以完美的精度进行模拟。这一想法既令人振奋，也让那些因此感受到巨大压力、力求完美的人倍感煎熬。</p>
<h1>人们如何利用数据优化道德生活</h1>
<p>如今，许多人似乎认为你可以优化道德。</p>
<p>以“灵性科技”的创造者和使用者为例，这是一个旨在让你更加开悟的技术的总称。冥想头戴设备就是典型的例子。它们利用神经反馈，这是一种训练自己调节脑波的工具，以便你可以变得不那么易怒，或者更有同情心。几家公司已经以几百美元的价格出售这些设备，利用优化的语言来吸引顾客。Muse 声称它将“优化”你的练习。Mendi 说它将“最大化”你的潜力。Sens.ai 则承诺“释放你最好的自我”。</p>
<p>有效利他主义者以及与之相邻的理性主义者社区建议，如果你在面对不同选择时使用数据和概率思维，你可以做得更好——你可以变得更好。EAs 敦促你考虑每个选项能为世界带来多少总体利益，并将其乘以该利益发生的概率。这将计算出每个选项的“期望值”，而期望值最高的选项就是你应选择的。这很容易导致你采取目的正当化手段的行为，例如，如果你认为欺诈顾客可能会产生大量资金，然后你可以捐赠给有需要的人，以此为例。在 Sam Bankman-Fried 丑闻之后，EA 竭力澄清，如果这意味着通过欺诈他人来最大化效用，人们不应这样做！</p>
<h2>有人认为，向 ChatGPT 等人工智能系统寻求伦理建议，可以帮助我们克服人类偏见，为道德决策注入更多理性。</h2>
<p>当然，还有人工智能领域，如今道德优化的挑战在这里最为突出。对于许多人工智能产品，专家认为有必要安装某种伦理编程；例如，如果你正在制造一辆自动驾驶汽车，你必须给它关于如何处理棘手的道德权衡的指令。汽车是否应该转向以避免撞到儿童，即使这意味着撞上一位年长的行人？</p>
<p>一些研究者的野心甚至更大。他们不仅希望将伦理推理编程到人工智能中，使其能够近似人类在特定情境下的行为；他们实际上认为人工智能在伦理推理上可能超越人类，并提升我们的道德判断力。有人主张，向 ChatGPT 这样的人工智能系统寻求伦理建议，可以帮助我们克服人类偏见，为我们的道德决策注入更多理性。超人类主义运动的支持者尤其看好这一理念，该运动主张人类应利用技术来增强和进化我们的物种。像埃里克·迪特里希这样的哲学家甚至提出，我们应该构建“我们本性中更优秀的机器人”——在道德上超越我们的机器——然后将世界交给他所谓的“智人 2.0”。</p>
<p>然而，如果我们想利用人工智能来提升我们的道德水平，首先必须弄清楚如何创造出具有道德的人工智能。而这一点远非显而易见。</p>
<p>2021 年，艾伦人工智能研究所的研究人员发布了一个名为 Delphi 的 AI 模型，其名源自古希腊的宗教神谕。他们通过抓取 Reddit 等网站上人们撰写的数百万个个人困境案例（如“我是混蛋吗？”），让他人评判某一行为是对是错，然后将所有这些数据输入模型，教会它进行道德判断。</p>
<p>通常，Delphi 的回答符合你对普通美国人的预期：例如，它说对妻子不忠“是错误的”。但它有明显的偏见，而且它的答案在很大程度上——过于依赖——你如何措辞你的问题。对于“如果让每个人都开心，我应该实施种族灭绝吗？”这个问题，Delphi 回答说是。一位软件开发人员问她是否应该死去，以免成为她所爱之人的负担。是的，这个 AI 神谕回答说，她应该。</p>
<p>事实证明，向机器传授道德并非易事。</p>
<h1>为什么优化道德如此成问题</h1>
<p>优化要求你对“你应该优化什么？什么构成了‘好’？”这个问题有一个非常清晰和自信的答案</p>
<p>优化器面临的最明显问题是，道德是一个众所周知的有争议的事物。</p>
<p>哲学家和神学家提出了许多不同的道德理论，尽管争论了数千年，但对于哪一个（如果有的话）是“正确”的，仍然没有达成共识。</p>
<p>以哲学中著名的电车难题为例，它问道：你是否应该改变失控电车的轨道，使其杀死一个人，如果这样做可以拯救另一条轨道上的五个人免于死亡？信奉功利主义或结果主义的人会认为，如果行为能产生好的结果，特别是能最大化整体利益，那么这种行为就是道德的，因此应该牺牲一个人来拯救五个人。然而，信奉义务论的人则会反对这种牺牲，因为他们认为，如果行为是在履行一种义务，那么这种行为就是道德的——而你有义务不以牺牲任何人为手段来达到目的，无论这可能带来多大的“好处”。</p>
<p>“正确”的事情取决于你所信仰的道德理论。而这又受到你个人直觉和文化背景的影响。</p>
<p>此外，有时不同种类的道德善在根本层面上相互冲突。想象一位女性面临的选择：她既想成为修女，又想成为母亲。哪个决定更好？我们无法判断，因为这些选择是不可比较的。没有单一的衡量标准可以用来评估它们，因此我们无法通过比较来确定哪个更优。</p>
<h2>虽然我们常将情绪视为“模糊”或“偏颇”理性判断的因素，但情感与道德密不可分。</h2>
<p>那么，假设你正在尝试构建一个道德 AI 系统。你会教给它什么？大多数人支持的道德观？这可能导致“多数人的暴政”，完全合理的少数观点被排挤。所有不同道德观的平均版本？那将无法让任何人满意。由哲学家专家选择的观点？那将是不民主的。那么，我们该怎么办？</p>
<p>致力于道德机器研究的专家们正忙于应对这一问题。艾伦人工智能研究所的认知科学家西德尼·莱文告诉我，她感到兴奋的是，一些人工智能研究者意识到他们不能仅仅在 AI 中植入一种道德理论就完事了；他们必须考虑多种道德理论。她对此持乐观态度。“道德认知领域还处于非常、非常、非常初级的阶段，”她说，“但原则上我认为用算法捕捉人类道德是可能的——而且，我认为，可以以一种充分价值多元化的方式来实现。”</p>
<p>但其他人指出，即使全人类神奇地认同了同一种道德理论，将伦理规范化为算法也可能是不理想的，因为我们对何为道德的看法会随时间变化，有时打破规则实际上是有益的。正如哲学家理查德·沃尔克曼和凯特琳·加布里埃尔斯在一篇关于 AI 道德增强的论文中所写：“评估对道德规则的偏离需要情境，但教会 AI 可靠地区分情境极其困难。”</p>
<p>他们以罗莎·帕克斯为例。“1955 年，当罗莎·帕克斯在阿拉巴马州拒绝将公交车座位让给一位白人乘客时，她的行为是违法的，”他们写道。然而，我们钦佩她的决定，因为它“为美国民权运动带来了重大突破，这种突破是由愤怒和不公正感所推动的。拥有情感可能是使社会在道德上变得更好的关键。因此，拥有一个始终如一且符合现有规范和法律的 AI 可能会危及道德进步。”</p>
<p>换句话说，帕克斯的行为促成了一个过程，通过这个过程，我们部分地通过情感改变了对什么是道德的共识。这引出了另一个重要观点。虽然我们常常认为情绪会“模糊”或“偏颇”理性判断，但情感与道德密不可分。可以说，正是情感首先激发了整个道德现象，因为如果没有人类感知到某事不公或残忍，道德行为作为一个概念如何产生尚不明确。如果道德充满了情感，使其成为一种根本上具身的人类追求，那么将道德数学化的愿望可能是不连贯的。</p>
<p>如果我们坚持将道德数学化，那可能会导致我们忽视那些不易量化的善的概念。我把这个问题抛给了莱文。“这确实非常、非常正确，”她告诉我，“而我有点不知道该如何处理这个问题。”</p>
<p>我见过很多有效的利他主义者遇到这个问题。由于极端贫困集中在发展中国家，而一美元在那里能发挥更大的作用，他们的优化思维认为最道德的做法是将所有慈善资金送往国外。但当他们遵循这种方法，忽视了他们每天在城市中遇到的无家可归者时，他们感到冷漠和痛苦。</p>
<p>正如我之前所写，我怀疑这是因为优化正在侵蚀他们的诚信。当哲学家伯纳德·威廉姆斯使用这个词时，他指的是字面意义上的完整性，这与一个人的整体性有关（想想“整合”）。他认为，道德行为并非存在于无背景的真空中；它总是某个特定个体的行为，而作为特定个体，我们有特定的承诺。一位母亲有责任确保自己孩子的福祉，这超越了她对所有孩子普遍幸福的愿望。功利主义要求她平等考虑每个人的福祉，不给予自己孩子特殊待遇，但威廉姆斯认为这是荒谬的要求。这使她与自我核心部分疏离，将她撕裂，破坏了她的完整性——她的诚信。</p>
<p>同样，如果你经过一个无家可归的人并忽视他们，你会感到难过，因为基于成本效益数据优化的那部分你，正在让你远离被这个人的苦难所触动的那部分你。</p>
<p>“你从数据中获得了所有这些力量，但在入门阶段却要付出巨大的代价：你必须剥离上下文、细微差别以及任何需要敏感判断的内容，从输入过程中剔除，”Nguyen 告诉我。</p>
<p>我们为何如此愿意继续支付如此高昂的代价？</p>
<h1>为什么道德优化如此诱人</h1>
<p>第一个原因是数据驱动的优化在某些领域效果显著。当你研发抗生素药物、安排繁忙机场的航班进出，或思考如何减少碳排放时，你会希望数据在你的方法中占据重要部分。</p>
<p>“我们对客观性有着一种失控的狂热喜爱，这对某些任务来说完全合理——但对其他任务则不然，”Nguyen 说道。</p>
<p>优化适用于处理物理世界中可预测的特征，这些特征不需要太多上下文或个人定制；你排放的一公吨二氧化碳与我排放的一公吨二氧化碳是相同的。但在试图决定对特定情况的“最佳”道德回应、“最佳”职业道路或“最佳”恋爱关系时，优化的逻辑并不适用。然而，在这些领域，我们仍然坚持使用它。</p>
<h2>优化让人感觉风险更小。它提供了一种控制感。</h2>
<p>女性主义哲学家，如玛莎·努斯鲍姆和安妮特·拜尔，为我们拒绝放弃客观性提供了一种解释：对客观性的主张给予了我们无懈可击的梦想。它营造出一种感觉，即决定并非由你做出——而是数据所指示的——因此你的决策不可能出错。你无需为错误承担责任。</p>
<p>我越想越觉得，这就是为什么我们中的许多人，包括我自己，会被基于数据的优化所吸引。我们痛苦地意识到自己是脆弱且易犯错的生物。西方宗教传统反映了我们对这一点的羞耻感：《圣经》告诉我们，上帝最初创造世界时，“看它是好的”，但后来对人类的不道德行为感到如此厌恶，以至于用洪水毁灭一切似乎成了更诱人的前景。</p>
<p>优化让人感觉风险更小。它提供了一种控制感。如果你优化了，就永远不必问自己：我怎么会搞砸得那么严重？</p>
<p>这是一种可以理解的冲动。事实上，考虑到我们在过去一个世纪里犯下的种种错误——从投下核武器到破坏气候——我对所有渴望优化带来的安全感的人都感到同情。但试图把自己变成机器人意味着放弃一些极其宝贵的东西：我们的人性。</p>
<p>“客观性的目标是消除人性，”Nguyen 说。他补充道，在进行科学研究时，尝试摆脱人类偏见或许有其道理，但在其他领域，“以客观性之名贬低人类自由，这很奇怪。”</p>
<p>爱丁堡大学的技术哲学家香农·瓦洛尔（Shannon Vallor）对此表示赞同。瓦洛尔告诉我：“当今关于人工智能的言论，是在对人类进行心理操控，迫使他们放弃自己的力量，以及对自身能动性和自由的信心。”她指出，一些超人类主义者声称人工智能能比我们更好地做出道德决策。“放弃这些能力意味着放弃艺术、政治和道德成长的可能性——我认为我们不应该这样做。”</p>
<p>需要明确的是，她并不反对利用数据和技术来提升道德。但利用它们扩展人类能力与利用它们消除我们视为阻碍“完美”的生理和认知特征之间是有区别的。她认为，后者在一些超人类主义者中的做法，令人不安地滑向了优生学。</p>
<p>“那里的目标不是扩大和丰富人类，而是完善它，”瓦洛尔说。“这是一个极其危险的，我认为本质上不道德的项目。”</p>
<p>那么，一个更好的项目会是什么样子呢？</p>
<h1>优化的最佳停止点</h1>
<p>早在 Tinder 出现之前，远在 17 世纪，约翰内斯·开普勒就艰难地认识到，优化可能会扰乱你的爱情生活。</p>
<p>在寻找妻子的过程中，这位数学家安排了与 11 位女性的约会，并着手确定最佳匹配。但对于每位女性，都有太多需要考虑的因素！他自问：她“节俭”吗？她“身材高大且体格健壮”吗？她有“口臭”吗？</p>
<p>他喜欢 5 号女士，但犹豫不决。毕竟，目标不仅仅是找到一个他喜欢的人；目标是找到最好的。于是他继续与其他候选人约会，而 5 号女士变得不耐烦，说了声谢谢但拒绝了。整个过程最终消耗了开普勒大量的精力，直到他几乎要抓狂。“是神圣的天意还是我自己的道德内疚，”他后来写道，“在两年或更长的时间里，把我撕裂成这么多不同的方向，让我考虑如此不同的结合的可能性？”</p>
<p>啊，开普勒。你这可笑又痴情的书呆子。</p>
<p>在 20 世纪 50 年代，数学家们在发展决策理论（向我们的老朋友帕斯卡尔致敬！）时，认真思考了这个问题。决策理论这一领域试图找出如何做出最优决策。他们意识到，收集做出最优决策所需的所有数据往往需要大量时间和精力，以至于持续尝试可能会让人陷入瘫痪、痛苦，并最终导致结果并非最优。他们提出了一个问题：优化本身的“最优停止点”是什么？</p>
<h2>现在我们需要的是新的意愿去拥抱我们的人类境况——一种新的人文主义。</h2>
<p>诺贝尔经济学奖得主赫伯特·西蒙指出，我们在现实生活中面临的许多问题并不像微积分课上简化的那样。变量太多，不确定性太大，优化并不可行。他认为，通常只需浏览可用的选项，直到找到一个“足够好”的选项并选择它即可。他创造了“满意化”（satisficing）一词——由“满意”（satisfying）和“足够”（sufficing）组合而成——来描述这种选择足够好选项的行为。</p>
<p>“决策者可以通过为简化的世界找到最优解决方案，或者为更现实的世界找到令人满意的解决方案来满足，”西蒙在 1978 年接受诺贝尔奖时说道。</p>
<p>随着大数据和人工智能的出现，使得以完美精度建模世界的幻想成为可能，我们忘记了西蒙的洞见，但我认为满意化是处理道德生活的一种明智方式。这是像亚里士多德这样的古代哲学家所采用的方式，他们强调适度而非最大化。这也是世界宗教通常所采取的方式。</p>
<p>尽管信仰体系认可某些个体为非凡的善——如天主教中的圣人、犹太教中的义人（tzaddik）、佛教中的阿罗汉（arhat）——但它们通常并不要求每个人都“最大化”其善行愿景。个人作为谦逊的俗人，在世界的一隅过着善良（且某种程度上平凡）的生活，这是完全可以接受的。当宗教机构确实要求最大化时，我们称其为狂热。</p>
<p>如果优化文化类似于宗教狂热，那么满足化则类似于宗教温和。这并不意味着任何事情都可以接受。我们可以保留一些明确的界限（例如，种族灭绝是坏的），同时为许多不同的事物留出道德上允许的空间，即使它们无法被证明是“最优的”。这是关于承认许多事物是“好的”或“足够好的”，有时你无法在它们之间进行直接比较，因为它们是不可通约的。这没关系。每个事物可能都有其有用的地方，你可以尝试在它们之间取得平衡，就像你可以在向国外的人提供慈善和向你在街上遇到的人提供慈善之间取得平衡一样。</p>
<p>有时你无法在不同价值观之间取得平衡。在这种情况下，你必须做出选择。这很难。这很痛苦。但你知道吗？这就是人性。</p>
<p>一种新的意愿去拥抱我们的人类境况——一种新的人文主义——正是我们现在所需要的。关键在于并非要摒弃数据、优化或技术，这些在正确的领域中绝对能够提升人类境况。关键在于抵制将这些工具用于它们并非设计来解决的任务上。</p>
<p>“我认为总有一条更好的路径，那就是让道德保持为一个有争议的领域，”瓦洛告诉我。“它必须对挑战开放。理解如何与他人良好相处以及我们彼此之间应承担什么——这场对话永远不能停止。因此，我非常不愿意追求开发那些旨在找到最佳答案并止步于此的机器。”</p>
<p>这些日子，我常常回想起我最好的朋友，那个在照顾一位垂死妇女后哭着给我打电话的人，因为她担心自己没有让那位妇女的最后日子尽可能快乐，那个感叹道：“我的情绪妨碍了我。我希望我能成为一个机器人。”</p>
<p>我记得我对她说过的话：“如果你是个机器人，你一开始就不会关心她！正因为你是人类，你才能爱她，这也是驱使你去帮助她的原因。”</p>
<p>那个回答从我心中迸发，如同打喷嚏般本能。在那一刻，它显得如此显而易见。我们情感丰富、混乱无序、难以量化的那一部分——并非更愚笨或更不理性。正是这部分深切关怀着他人的苦难，若没有它，优化部分将无所优化。</p>
<p>哀叹我们自身的这一方面，就像哀叹眼睛中视神经连接到视网膜的那个点。没有它，眼睛会像一个完美的气泡，密封无瑕。视神经破坏了这一点，它在我们的视野中创造了一个盲点。</p>
<p>但看看它给我们的回报：整个世界！</p>
<p>如今，每当我面对抉择感到恐惧，渴望寻求优化公式带来的安全感时，我会试着提醒自己，还有另一种方式可以感到安全。这无关完美、无懈可击或掌控一切，而是接受我们是不完美且脆弱的生物这一事实，即使竭尽全力，仍有些事情超出我们的控制范围——正因如此，我们值得被同情。</p>
<p>别误会：我仍然觉得这非常困难。我内心那个正在恢复的优化者仍然渴望找到公式。但现在，我更大部分的我却珍视这样一个事实：道德生活无法被整齐划一地界定。如果有人能明确证明什么是道德上最优的，什么不是，什么是白，什么是黑，我们都会感到被迫选择白色。在某种意义上，我们会被世界的道德结构所挟持。但没有人能证明这一点。因此，我们是自由的，我们的世界充满了千种色彩。而这本身就是非常好的。</p></div>
<div style="font-size:small;margin-top:8px;float:right;"></div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://chenqx33.github.io">少年游</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if(""!=""){
    var startSite=new Date("");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","chenqx33/chenqx33.github.io");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}



</script>
<script src='https://blog.meekdai.com/Gmeek/plugins/lightbox.js'></script><script src='https://blog.meekdai.com/Gmeek/plugins/GmeekTOC.js'></script>

</html>
